{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4d66a8b-75c7-450d-97de-adc1bbbca74c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as st \n",
    "from scipy.stats import norm\n",
    "from scipy.stats import burr12\n",
    "from scipy.fft import fft, ifft\n",
    "import scipy.linalg as linalg\n",
    "from scipy.optimize import minimize\n",
    "import collections \n",
    "import time\n",
    "from itertools import chain\n",
    "import timeit\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d00977-53ea-48b7-8ab0-c83ada359a2e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Part 0: definition of the kernels and some functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "95bdbcbf-0458-4cab-acb5-2ad774552aaf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def kernel_k1(x, y):\n",
    "    return 1 if x > 0 and y > 0 else 0\n",
    "\n",
    "def kernel_k2(x, y):\n",
    "    return x * y\n",
    "\n",
    "def kernel_k3(x, y):\n",
    "    return (x + y) if x > 0 and y > 0 else 0\n",
    "\n",
    "def kernel_k4(x, y):\n",
    "    return 1/4*(x**(1/3) + y**(1/3))**3 if x > 0 and y > 0 else 0\n",
    "\n",
    "def kernel_ka05(x,y):\n",
    "    return (x*y)**0.5\n",
    "\n",
    "def kernel_ka2(x,y):\n",
    "    return (x*y)**0.8\n",
    "\n",
    "def kernel_ka3(x,y):\n",
    "    return (x*y)**0.9\n",
    "    \n",
    "kernel_functions = {\n",
    "    'kernel_k1': kernel_k1,\n",
    "    'kernel_k2': kernel_k2,\n",
    "    'kernel_k3': kernel_k3,\n",
    "    'kernel_k4': kernel_k4,\n",
    "    'kernel_ka05': kernel_ka1,\n",
    "    'kernel_ka2': kernel_ka2,\n",
    "    'kernel_ka3': kernel_ka3,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f4b50c2-31aa-4ee4-9eae-90cfa1dc3670",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def kernel_sum(particles, kernel):\n",
    "    '''\n",
    "    old inefficient function to compute K(x,y) the entries of our kernels and \n",
    "    the denominator to use in the index distribution\n",
    "    '''\n",
    "    start = timeit.default_timer()\n",
    "    n = len(particles)\n",
    "    weights = np.zeros((n, n))\n",
    "    \n",
    "    kernel = kernel_functions[kernel]\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if i != j:\n",
    "                weights[i, j] = kernel(particles[i], particles[j])\n",
    "                \n",
    "    total_weight = np.sum(weights)\n",
    "    stop = timeit.default_timer()\n",
    "    return weights, total_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9c6ecf-21b7-4a48-9ca0-e74da4fc3235",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5a6629e-b8a7-425f-be1f-1f11f4721697",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def kernel_sum_triangular(particles, kernel):\n",
    "    '''\n",
    "    more optimal function to compute K(x,y) the entries of our kernels and \n",
    "    the denominator to use in the index distribution\n",
    "    '''\n",
    "    \n",
    "    start = timeit.default_timer()\n",
    "    n = len(particles)\n",
    "    weights = np.zeros((n, n))\n",
    "    \n",
    "    kernel = kernel_functions[kernel]\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "                weights[i, j] = kernel(particles[i], particles[j])\n",
    "    \n",
    "    weights += np.triu(weights, 1).T  \n",
    "    \n",
    "    total_weight = np.sum(weights)\n",
    "    stop = timeit.default_timer()\n",
    "    #print(\"Tri\",stop - start)\n",
    "    return weights, total_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4272f31a-a23e-4413-93f8-53ac4139e2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_P_index(particles, kernel):\n",
    "    '''\n",
    "    function that calculates the index distribution matrix\n",
    "    '''\n",
    "    \n",
    "    weights, total_weight = kernel_sum_triangular(particles, kernel)\n",
    "    \n",
    "    P_index = weights / total_weight\n",
    "\n",
    "    return P_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e6ae0e7-ad78-4696-a9e1-0500db120589",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def majorant_kernel(particles,kernel):\n",
    "    '''\n",
    "    function to calculate the majorant kernel as the maximum value of the collision kernel\n",
    "    '''\n",
    "    kernel_func = kernel_functions[kernel]\n",
    "    weights, total_weight = kernel_sum_triangular(particles, kernel)\n",
    "    return np.argmax(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ede7000-1355-4e4b-a18c-31f60aa38de5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def AR_sampling(particles, kernel, recursion_counter=0):\n",
    "    '''\n",
    "    Acceptance-Rejection algorithm sampling function, \n",
    "    as majorant kernel we choose the maximum value of the kernel\n",
    "    '''\n",
    "    start = timeit.default_timer()\n",
    "\n",
    "    kernel_func = kernel_functions[kernel]\n",
    "    Max = majorant_kernel(particles, kernel)\n",
    "\n",
    "    U = random.uniform(0, 1)\n",
    "    row_index = random.randint(0, len(particles) - 1)\n",
    "    col_index = random.randint(0, len(particles) - 1)\n",
    "    while col_index == row_index:\n",
    "        col_index = random.randint(0, len(particles) - 1)\n",
    "        row_index = random.randint(0, len(particles) - 1)\n",
    "\n",
    "    if U <= kernel_func(row_index, col_index) / Max:\n",
    "        i, j = row_index, col_index\n",
    "\n",
    "        stop = timeit.default_timer()\n",
    "        print(\"AR time:\", stop - start, \"iterations:\", recursion_counter)\n",
    "\n",
    "        return i, j\n",
    "\n",
    "    else:\n",
    "        recursion_counter += 1\n",
    "        return AR_sampling(particles, kernel, recursion_counter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be02d769-c52e-43e0-bb90-58e87118e853",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def inverse_sampling(particles, kernel):\n",
    "    '''\n",
    "    function to sample from the index distribution in a simple way: \n",
    "    '''\n",
    "    start = timeit.default_timer()\n",
    "    \n",
    "    U = random.uniform(0, 1)\n",
    "    \n",
    "    P_idx = calculate_P_index(particles, kernel)\n",
    "    \n",
    "    flat_index = np.where(np.cumsum(P_idx) >= U)[0][0]\n",
    "    \n",
    "    #get the 2D index from the flat one\n",
    "    i, j = np.unravel_index(flat_index, P_idx.shape)\n",
    "    \n",
    "    stop = timeit.default_timer() \n",
    "    return i,j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "823ff404-0a72-4a93-a36f-99f91fd17683",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def transition_matrix(i,j, N):\n",
    "    '''\n",
    "    function to compute the transition matrix for index i,j \n",
    "    for the Markov process described in (3) from the project description\n",
    "    '''\n",
    "    M = np.eye(N)\n",
    "    M[i][j]=1\n",
    "    M[j][j]=0\n",
    "    \n",
    "    return M\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3bb9b3-920c-4459-8a48-9274be9dedd1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Part 1: Simulate the coagulation process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a410fb80-c983-4d61-88b2-2f5232e99fc6",
   "metadata": {},
   "source": [
    "To simulate the dynamics we start by generating a starting population. We wait an exponentially distributed time step computed from the kernel, we sample the collision indices from the index distribution, find the new state of the system with the help of the transition matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e3e7bde-2b5e-4310-ae6b-714a6a3b43d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def simulate_coagulation(N, T, X0, kernel):\n",
    "    '''\n",
    "    To simulate the dynamics we start by generating a starting population.\n",
    "    We wait an exponentially distributed time step computed from the kernel,\n",
    "    we sample the collision indices from the index distribution, \n",
    "    find the new state of the system with the help of the transition matrix.\n",
    "    '''\n",
    "    \n",
    "    kernel_func = kernel_functions[kernel] \n",
    "    \n",
    "    current_time = 0\n",
    "    jump_count = 0\n",
    "\n",
    "    Xt = [X0]\n",
    "    t = [current_time]\n",
    "    \n",
    "    while current_time < T:\n",
    "        \n",
    "        # Calculate lambda \n",
    "        start1 = timeit.default_timer()\n",
    "        weights, total_weight = kernel_sum_triangular(X0, kernel)\n",
    "        stop1 = timeit.default_timer()\n",
    "        \n",
    "        Lambda = total_weight/(2*N)\n",
    "        \n",
    "        # Generate waiting time Sn\n",
    "        Sn= st.expon.rvs(scale=1/Lambda)\n",
    "        \n",
    "        # Increment current time by the waiting time\n",
    "        current_time += Sn \n",
    "        jump_count +=1\n",
    "        \n",
    "        #sample index for collision\n",
    "        start2 = timeit.default_timer()\n",
    "        #i,j = AR_sampling(X0, kernel = kernel)\n",
    "        i,j = inverse_sampling(X0, kernel=kernel)\n",
    "        stop2 = timeit.default_timer()\n",
    "        \n",
    "        #find new vector of sizes based on transition matrix\n",
    "        M = transition_matrix(i,j,N)\n",
    "        X0 = M.dot(X0)\n",
    "        Xt.append(X0.copy()) \n",
    "        t.append(current_time)\n",
    "        \n",
    "        #end if we reached the maximum jump number\n",
    "        if jump_count == N-1:\n",
    "            break\n",
    "            \n",
    "   \n",
    "    return Xt,t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54000ec0-1418-4168-ade0-b7318c4ba372",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Part 2 & 3: Monte Carlo simulation of concentration, moment, and gelation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a756e254-45a0-4087-8977-f20d98effe72",
   "metadata": {
    "tags": []
   },
   "source": [
    "## First we define the functions and the main monte carlo algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2e84aca1-b906-46a9-8156-e8880da27778",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define the 3 average parameters to be studied: average concentration, moment 1.5, gelation G\n",
    "\n",
    "def average_conc(X,k, N):\n",
    "    counts = []\n",
    "    \n",
    "    for arr in X:\n",
    "        count = np.count_nonzero(arr == k)\n",
    "        counts.append(count/N)\n",
    "        \n",
    "    return counts\n",
    "\n",
    "def moments(X,p):\n",
    "    X = np.array(X)\n",
    "    mom_p = np.mean(X**p, axis= 1)\n",
    "    return mom_p\n",
    "\n",
    "\n",
    "def gelation(X, N):\n",
    "    X = np.array(X)\n",
    "    G =  np.max(X, axis=1)/N\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "268c79f9-4435-4fe6-af34-e1a748f02eda",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def MC_coagulation(N, T, R, k, X0,p, kernel, Z):\n",
    "    '''\n",
    "    here is the main algorithm for generating R iid replicas of the variables previously defined\n",
    "    (concentration, moments, gelation)\n",
    "    '''\n",
    "    \n",
    "    Xi = []\n",
    "    Zi = []\n",
    "    Ji = []\n",
    "    \n",
    "    start1 = timeit.default_timer()\n",
    "    \n",
    "    #repeat the coagulation simulation R times\n",
    "    for r in range(R):\n",
    "        \n",
    "        #simulate coagulation to generate the vectors in time\n",
    "        Xt, t = simulate_coagulation(N=N, T=T, X0=X0, kernel=kernel)\n",
    "        \n",
    "        #calculate the average parameters and store them along with the jumping times\n",
    "        if Z == \"average_conc\":\n",
    "            z = average_conc(Xt, k, N)\n",
    "            #print(\"Xt and average computed for conc\")\n",
    "        if Z == \"moments\":\n",
    "            z = moments(Xt,p)\n",
    "            #print(\"Xt and average computed for mom\")\n",
    "        if Z == \"gelation\":\n",
    "            z = gelation(Xt,N)\n",
    "            #print(\"Xt and average computed for gel\")\n",
    "        \n",
    "        Zi.append(z)\n",
    "        Ji.append(t)\n",
    "    Zi = np.array(Zi)   \n",
    "    return Zi, Ji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "eca821e3-25c9-4cfc-ae29-9daeeccc6822",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def average_MC(Zi,Ji, N):\n",
    "    '''\n",
    "    function for Monte Carlo method that calculates the sample mean estimator\n",
    "    and asymptotic confidence intervals\n",
    "    '''\n",
    "    #confidence level for intervals\n",
    "    alpha = 0.05\n",
    "    \n",
    "    #here we create a unique list of sorted jumping times \n",
    "    J_no_first = [sublist[1:] for sublist in Ji] \n",
    "    J_no_first[0].append(0)\n",
    "    J_sorted = sorted(list(chain.from_iterable(J_no_first)))\n",
    "    J_sorted=np.array(J_sorted)\n",
    "\n",
    "    Ji = np.array(Ji) \n",
    "    \n",
    "    means = []\n",
    "    Z_mean = []\n",
    "    sigma = []\n",
    "    \n",
    "    #for each jumping time we find the maximum value lower than that in each row of times and \n",
    "    #find the corresponding indices in the rows of Zi\n",
    "    #with this we can generate the means of our parameters\n",
    "    for j_time in J_sorted:\n",
    "        Z_mean = []\n",
    "        for i, time_seq in enumerate(Ji):\n",
    "            # Find the index of the last time less than or equal to j_time\n",
    "            valid_indices = np.where(time_seq <= j_time)[0]\n",
    "            last_index = valid_indices[-1]\n",
    "            Z_mean.append(Zi[i][last_index])\n",
    "\n",
    "                \n",
    "        Z_mean = np.array(Z_mean)\n",
    "        means.append(np.nanmean(Z_mean))\n",
    "        sigma.append(np.nanstd(Z_mean, ddof=1))\n",
    " \n",
    "    \n",
    "    means = np.array(means)\n",
    "    sigma = np.array(sigma)\n",
    "\n",
    "    #calculate confidence intervals\n",
    "    c_ok = st.norm.ppf(1-alpha/2)\n",
    "    lower_bound = means - c_ok*sigma/np.sqrt(R)\n",
    "    upper_bound = means + c_ok*sigma/np.sqrt(R) \n",
    "    \n",
    "    stop2 = timeit.default_timer()\n",
    "    \n",
    "    return means, sigma, J_sorted, lower_bound, upper_bound\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c61b187-81fa-4e26-8843-5bf0d3770ab8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Let's produce and save simulation files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1b2e6e2e-0dee-4dc6-b3c6-390fc5d9992c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define simulation parameters\n",
    "N_values = [100]\n",
    "k_values = [1,2,3,4,5] # put this to one element if not concentration!!\n",
    "p = 1.5\n",
    "#kernels = [\"kernel_k4\",\"kernel_k3\"]\n",
    "kernels = [\"kernel_k2\",]\n",
    "Z = \"average_conc\"\n",
    "#Z = \"moments\"\n",
    "#Z = \"gelation\"\n",
    "R = 10\n",
    "\n",
    "# Directory to store results. create subfolders for each Z otherwise they will overwrite possibly\n",
    "results_dir = \"simulation_results/concentration\"\n",
    "os.makedirs(results_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ee9626aa-6388-4c5e-99b3-9e06139c2ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved results to simulation_results/xEmilio/results_N100_k1_kernel_k2_R10.pkl\n",
      "Saved results to simulation_results/xEmilio/results_N100_k2_kernel_k2_R10.pkl\n",
      "Saved results to simulation_results/xEmilio/results_N100_k3_kernel_k2_R10.pkl\n",
      "Saved results to simulation_results/xEmilio/results_N100_k4_kernel_k2_R10.pkl\n",
      "Saved results to simulation_results/xEmilio/results_N100_k5_kernel_k2_R10.pkl\n"
     ]
    }
   ],
   "source": [
    "# Loop over parameters and run simulations\n",
    "for N in N_values:\n",
    "    X0 = np.ones(N)\n",
    "    for kernel in kernels:\n",
    "        for k in k_values:\n",
    "            # Run simulation\n",
    "            Zi, Ji = MC_coagulation(N, T=10, R=R, k=k, X0=X0, p=p, kernel=kernel, Z=Z)\n",
    "\n",
    "            # Compute averages\n",
    "            means, sigma, J_sorted, lower_bound, upper_bound = average_MC(Zi, Ji, N)\n",
    "\n",
    "            # Prepare result dictionary\n",
    "            result = {\n",
    "                \"means\": means,\n",
    "                \"sigma\": sigma,\n",
    "                \"J_sorted\": J_sorted,\n",
    "                \"lower_bound\": lower_bound,\n",
    "                \"upper_bound\": upper_bound\n",
    "            }\n",
    "\n",
    "            # Save result to file\n",
    "            filename = f\"results_N{N}_k{k}_{kernel}_R{R}.pkl\"\n",
    "            filepath = os.path.join(results_dir, filename)\n",
    "            with open(filepath, \"wb\") as f:\n",
    "                pickle.dump(result, f)\n",
    "\n",
    "            print(f\"Saved results to {filepath}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
